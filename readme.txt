GBDT的简单实现

回归、二分类、多分类

可视化


核心代码：
decisionTree.py
用于生成一棵单独的决策树作为基模型

GBDT.py
GBDT算法核心， 主要包括 fit 和 predict 两个功能

lossFunction.py
每次训练更新模型时需要计算的残差，更新叶子节点的预测值，更新训练损失，以及基模型 F_0 的初始化


main.py
数据读取-->初始化GBDT模型-->模型训练-->初始化基模型F_0-->
更新下一轮迭代需要的损失-->进入迭代循环-->计算当前迭代轮次需要拟合的残差-->
生成当前轮次的基模型f_m-->更新残差-->迭代循环结束-->模型训练结束-->
模型预测


生成当前轮次的决策树f_m的具体流程：
读取节点的数据子集-->判断是否满足继续分裂的条件（树继续生长的条件）-->
选择用于分裂的特征-->通过计算选择特征的最优分裂值-->生成左子树和右子树（通过递归调用生成）



